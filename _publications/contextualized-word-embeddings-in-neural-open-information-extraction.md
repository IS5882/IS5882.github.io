---
title: "Contextualized Word Embeddings in a Neural Open Information Extraction Model"
collection: publications
permalink: /publication/contextualized-word-embeddings-in-neural-open-information-extraction
excerpt: 'Open Information Extraction (OIE) is a challenging task of extracting relation tuples from an unstructured corpus. While several OIE algorithms have been developed in the past decade, only few employ deep learning techniques. In this paper, a novel OIE neural model that leverages Recurrent Neural Networks (RNN) using Gated Recurrent Units (GRUs) is presented. Moreover, we integrate the innovative contextual word embeddings into our OIE model, which further enhances the performance. The results demonstrate that our proposed neural OIE model outperforms the existing state-of-art on two datasets.'
date: 2019-06-21
venue: 'International Conference on Applications of Natural Language to Information Systems'
paperurl: 'https://link.springer.com/chapter/10.1007/978-3-030-23281-8_31'
citation: '<b>Injy Sarhan</b> and Marco R. Spruit. <i>"Contextualized Word Embeddings in a Neural Open Information Extraction Model."</i>, International Conference on Applications of Natural Language to Information Systems. Springer  England. (2019, June).'
---
Open Information Extraction (OIE) is a challenging task of extracting relation tuples from an unstructured corpus. While several OIE algorithms have been developed in the past decade, only few employ deep learning techniques. In this paper, a novel OIE neural model that leverages Recurrent Neural Networks (RNN) using Gated Recurrent Units (GRUs) is presented. Moreover, we integrate the innovative contextual word embeddings into our OIE model, which further enhances the performance. The results demonstrate that our proposed neural OIE model outperforms the existing state-of-art on two datasets.

[Download paper here](https://link.springer.com/chapter/10.1007/978-3-030-23281-8_31).